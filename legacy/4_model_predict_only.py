# -*- coding: utf-8 -*-
"""
4_model_predict_only.py
- ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰
- ìƒë‹´ í’ˆì§ˆ ë¶„ë¥˜: ë§Œì¡±, ë¯¸í¡, í•´ê²° ë¶ˆê°€, ì¶”ê°€ ìƒë‹´ í•„ìš”
"""

import pandas as pd
import numpy as np
import pickle
import os
from pathlib import Path
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import lightgbm as lgb

def load_trained_model(model_path="trained_models"):
    """í•™ìŠµëœ ëª¨ë¸ê³¼ ì¸ì½”ë”ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    model_dir = Path(model_path)
    
    try:
        # ëª¨ë¸ íŒŒì¼ë“¤ í™•ì¸
        model_file = model_dir / "counseling_quality_model.pkl"
        encoder_file = model_dir / "label_encoder.pkl"
        feature_names_file = model_dir / "feature_names.pkl"
        categorical_encoders_file = model_dir / "categorical_encoders.pkl"
        
        if not all([model_file.exists(), encoder_file.exists(), feature_names_file.exists()]):
            print("âŒ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.")
            return None, None, None, None
        
        # ëª¨ë¸ê³¼ ì¸ì½”ë” ë¡œë“œ
        with open(model_file, 'rb') as f:
            model = pickle.load(f)
        
        with open(encoder_file, 'rb') as f:
            label_encoder = pickle.load(f)
        
        with open(feature_names_file, 'rb') as f:
            feature_names = pickle.load(f)
        
        # ë²”ì£¼í˜• ì¸ì½”ë” ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        categorical_encoders = {}
        if categorical_encoders_file.exists():
            with open(categorical_encoders_file, 'rb') as f:
                categorical_encoders = pickle.load(f)
        
        print(f"âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   - ë¶„ë¥˜ í´ë˜ìŠ¤: {label_encoder.classes_}")
        print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(feature_names)}")
        print(f"   - ë²”ì£¼í˜• ì¸ì½”ë”: {len(categorical_encoders)}ê°œ")
        
        return model, label_encoder, feature_names, categorical_encoders
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None

def predict_counseling_quality():
    """ìƒë‹´ í’ˆì§ˆ ì˜ˆì¸¡ ì‹¤í–‰"""
    print("="*60)
    print("ìƒë‹´ í’ˆì§ˆ ë¶„ë¥˜ ì˜ˆì¸¡ ì‹œì‘")
    print("="*60)
    
    # 1) í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    model, label_encoder, feature_names, categorical_encoders = load_trained_model()
    if model is None:
        print("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ì–´ì„œ ì˜ˆì¸¡ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False
    
    # 2) ìƒˆë¡œìš´ ë°ì´í„° ë¡œë“œ (íŠ¹ì„± ì¶”ì¶œëœ ë°ì´í„°)
    try:
        feature_file = "output/text_features_all_v4.csv"
        if not Path(feature_file).exists():
            print(f"âŒ íŠ¹ì„± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {feature_file}")
            return False
        
        df_features = pd.read_csv(feature_file, encoding='utf-8-sig')
        
        # ì¤‘ë³µ í–‰ ì œê±°
        df_features = df_features.drop_duplicates(subset=['session_id'])
        
        # session_idë¥¼ ë¬¸ìì—´ë¡œ í†µì¼
        df_features['session_id'] = df_features['session_id'].astype(str)
        
        print(f"ğŸ“Š ì˜ˆì¸¡í•  ì„¸ì…˜ ìˆ˜: {len(df_features)}")
        
        # 3) ë ˆì´ë¸” íŒŒì¼ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        labels_file = "columns_extraction_all/preprocessing/session_labels.csv"
        df_labels = None
        if Path(labels_file).exists():
            df_labels = pd.read_csv(labels_file, encoding='utf-8-sig', dtype={'session_id': str})
            print(f"ğŸ“‹ ë ˆì´ë¸” ì •ë³´: {len(df_labels)}ê°œ ì„¸ì…˜")
        
        # 4) ë°ì´í„° ë³‘í•© (ë ˆì´ë¸”ì´ ìˆëŠ” ê²½ìš°)
        if df_labels is not None:
            df = df_features.merge(df_labels, on='session_id', how='left')
        else:
            df = df_features.copy()
            df['result_label'] = None
        
        # 5) ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”© (í•™ìŠµì‹œì™€ ë™ì¼í•˜ê²Œ)
        for col, encoder in categorical_encoders.items():
            if col in df.columns:
                print(f"   ë²”ì£¼í˜• ì¸ì½”ë”©: {col}")
                # ëª¨ë¥´ëŠ” ê°’ì€ 'missing'ìœ¼ë¡œ ì²˜ë¦¬
                original_values = df[col].fillna('missing').astype(str)
                try:
                    df[col] = encoder.transform(original_values)
                except ValueError as e:
                    # ìƒˆë¡œìš´ ê°’ì´ ìˆëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                    print(f"   ìƒˆë¡œìš´ ë²”ì£¼ ë°œê²¬ ({col}), ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬")
                    known_classes = set(encoder.classes_)
                    df[col] = [encoder.transform(['missing'])[0] if val not in known_classes else encoder.transform([val])[0] 
                              for val in original_values]
        
        # 6) íŠ¹ì„± ì„ íƒ ë° ìˆœì„œ ë§ì¶¤
        print(f"\nğŸ”§ íŠ¹ì„± ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŠ¹ì„±ë“¤ë§Œ ì„ íƒ
        missing_features = []
        available_features = []
        
        for feature in feature_names:
            if feature in df.columns:
                available_features.append(feature)
            else:
                missing_features.append(feature)
                # ëˆ„ë½ëœ íŠ¹ì„±ì€ 0ìœ¼ë¡œ ì±„ì›€
                df[feature] = 0
                available_features.append(feature)
        
        if missing_features:
            print(f"   âš ï¸ ëˆ„ë½ëœ íŠ¹ì„± {len(missing_features)}ê°œë¥¼ 0ìœ¼ë¡œ ì±„ì›€: {missing_features[:5]}...")
        
        # íŠ¹ì„± ë°ì´í„° ì¤€ë¹„ (í•™ìŠµì‹œì™€ ë™ì¼í•œ ìˆœì„œ)
        X_predict = df[feature_names].copy()
        
        # NaN ì²˜ë¦¬
        X_predict.fillna(0, inplace=True)
        
        # ë°ì´í„° íƒ€ì… ë³€í™˜ (í•™ìŠµì‹œì™€ ë™ì¼)
        for col in feature_names:
            X_predict[col] = pd.to_numeric(X_predict[col], errors='coerce').fillna(0)
        
        print(f"   âœ… ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_predict.shape}")
        print(f"   ë°ì´í„° íƒ€ì…: {X_predict.dtypes.value_counts().to_dict()}")
        
        # 7) ì˜ˆì¸¡ ìˆ˜í–‰
        print("\nğŸ”® ìƒë‹´ í’ˆì§ˆ ì˜ˆì¸¡ ì¤‘...")
        y_pred_proba = model.predict_proba(X_predict)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # 8) ê²°ê³¼ ì •ë¦¬
        predicted_labels = label_encoder.inverse_transform(y_pred)
        max_probabilities = np.max(y_pred_proba, axis=1)
        
        # 9) ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì •ë¦¬
        results_df = df[['session_id']].copy()
        results_df['predicted_label'] = predicted_labels
        results_df['confidence'] = max_probabilities
        
        # ì‹¤ì œ ë ˆì´ë¸” ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if 'result_label' in df.columns:
            results_df['actual_label'] = df['result_label']
        
        # ì‹¤ì œ ë ˆì´ë¸”ì´ ìˆëŠ” ê²½ìš° ì •í™•ë„ ê³„ì‚°
        if df_labels is not None and 'result_label' in df.columns:
            mask = df['result_label'].notna()
            if mask.sum() > 0:
                y_true = label_encoder.transform(df.loc[mask, 'result_label'])
                y_pred_labeled = y_pred[mask]
                
                accuracy = accuracy_score(y_true, y_pred_labeled)
                print(f"\nğŸ“ˆ ì˜ˆì¸¡ ì •í™•ë„: {accuracy:.4f}")
                
                # ë¶„ë¥˜ ë¦¬í¬íŠ¸ (í´ë˜ìŠ¤ê°€ 1ê°œ ì´ìƒì¼ ë•Œë§Œ)
                unique_classes = len(np.unique(y_true))
                if unique_classes > 1:
                    print("\nğŸ“Š ë¶„ë¥˜ ì„±ëŠ¥ ë³´ê³ ì„œ:")
                    print(classification_report(y_true, y_pred_labeled, 
                                              target_names=label_encoder.classes_))
                else:
                    print(f"\nğŸ“Š ë¶„ë¥˜ ê²°ê³¼: ëª¨ë“  ìƒ˜í”Œì´ ë™ì¼í•œ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡ë¨")
                    predicted_class = label_encoder.inverse_transform([y_pred_labeled[0]])[0]
                    print(f"   ì˜ˆì¸¡ëœ í´ë˜ìŠ¤: {predicted_class}")
        
        # 10) ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬
        pred_counts = pd.Series(predicted_labels).value_counts()
        print(f"\nğŸ“‹ ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:")
        for label, count in pred_counts.items():
            percentage = count / len(predicted_labels) * 100
            print(f"   {label}: {count}ê°œ ({percentage:.1f}%)")
        
        # 11) ê²°ê³¼ ì €ì¥
        output_dir = Path("results")
        output_dir.mkdir(exist_ok=True)
        
        results_file = output_dir / "counseling_quality_predictions.csv"
        results_df.to_csv(results_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {results_file}")
        
        # 12) ìƒìœ„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        print(f"\nğŸ” ì˜ˆì¸¡ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):")
        preview_df = results_df.head()
        for _, row in preview_df.iterrows():
            actual_info = f" (ì‹¤ì œ: {row.get('actual_label', 'N/A')})" if 'actual_label' in row else ""
            print(f"   ì„¸ì…˜ {row['session_id']}: {row['predicted_label']} (ì‹ ë¢°ë„: {row['confidence']:.3f}){actual_info}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def check_trained_models():
    """í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    model_dir = Path("trained_models")
    required_files = [
        "counseling_quality_model.pkl",
        "label_encoder.pkl", 
        "feature_names.pkl"
    ]
    
    all_exist = all((model_dir / f).exists() for f in required_files)
    return all_exist

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ìƒë‹´ í’ˆì§ˆ ë¶„ë¥˜ ëª¨ë¸ (ì˜ˆì¸¡ ì „ìš©)")
    print("="*50)
    
    # í•™ìŠµëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
    if not check_trained_models():
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € train_from_dataset_v4.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.")
        return False
    else:
        print("âœ… í•™ìŠµëœ ëª¨ë¸ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return predict_counseling_quality()

if __name__ == "__main__":
    main() 