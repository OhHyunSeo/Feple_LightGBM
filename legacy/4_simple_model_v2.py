# -*- coding: utf-8 -*-
"""
4. ìƒë‹´ í’ˆì§ˆ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (LightGBM)
ë¡œì»¬ í™˜ê²½ìš©ìœ¼ë¡œ ìˆ˜ì •ë¨
"""

import os
import pandas as pd
import numpy as np
import pickle
import lightgbm as lgb
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.utils.class_weight import compute_class_weight
from lightgbm import LGBMClassifier, early_stopping, log_evaluation
from tqdm import tqdm

def main():
    print("="*60)
    print("ìƒë‹´ í’ˆì§ˆ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print("="*60)
    
    # 1) ë°ì´í„° ë¡œë“œ
    print("\n[1ë‹¨ê³„] ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        train = pd.read_csv('dataset/train.csv', encoding='utf-8-sig')
        val   = pd.read_csv('dataset/val.csv',   encoding='utf-8-sig')
        test  = pd.read_csv('dataset/test.csv',  encoding='utf-8-sig')
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"   Train: {train.shape}, Val: {val.shape}, Test: {test.shape}")
    except FileNotFoundError as e:
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("   ë¨¼ì € 1-3ë‹¨ê³„ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return False
    
    # 2) ë ˆì´ë¸” ì¸ì½”ë”©
    print("\n[2ë‹¨ê³„] ë ˆì´ë¸” ì¸ì½”ë”© ì¤‘...")
    
    # ëª¨ë“  ë°ì´í„°ì˜ ë ˆì´ë¸” ìˆ˜ì§‘
    all_targets = pd.concat([
        train['result_label'],
        val['result_label'],
        test['result_label']
    ]).astype(str)
    
    # ë ˆì´ë¸” ì¸ì½”ë” ìƒì„± ë° í•™ìŠµ
    label_encoder = LabelEncoder().fit(all_targets)
    
    # ê° ë°ì´í„°ì…‹ì— ì ìš©
    for df in [train, val, test]:
        df['label_id'] = label_encoder.transform(df['result_label'].astype(str))
    
    print(f"âœ… ë ˆì´ë¸” í´ë˜ìŠ¤: {list(label_encoder.classes_)}")
    print(f"   í´ë˜ìŠ¤ ê°œìˆ˜: {len(label_encoder.classes_)}")
    
    # 3) ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©
    print("\n[3ë‹¨ê³„] ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”© ì¤‘...")
    
    categorical_cols = []
    encoders = {}
    
    # ì¡´ì¬í•˜ëŠ” ë²”ì£¼í˜• ì»¬ëŸ¼ë§Œ ì¸ì½”ë”©
    potential_cats = ['sent_label', 'mid_category', 'content_category', 'rec_place']
    for col in potential_cats:
        if col in train.columns:
            categorical_cols.append(col)
            
            # ì „ì²´ ë°ì´í„°ì˜ ê³ ìœ ê°’ìœ¼ë¡œ ì¸ì½”ë” í•™ìŠµ
            all_vals = pd.concat([train[col], val[col], test[col]]).astype(str)
            encoder = LabelEncoder().fit(all_vals)
            encoders[col] = encoder
            
            # ê° ë°ì´í„°ì…‹ì— ì ìš©
            for df in [train, val, test]:
                df[f'{col}_id'] = encoder.transform(df[col].astype(str))
    
    print(f"âœ… ì¸ì½”ë”©ëœ ë²”ì£¼í˜• ì»¬ëŸ¼: {categorical_cols}")
    
    # 4) íŠ¹ì„± ì„ íƒ
    print("\n[4ë‹¨ê³„] í•™ìŠµìš© íŠ¹ì„± ì„ íƒ ì¤‘...")
    
    # ì œì™¸í•  ì»¬ëŸ¼ë“¤ ì •ì˜
    exclude_cols = (
        ['session_id', 'result_label', 'label_id'] +
        categorical_cols +  # ì›ë³¸ ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤
        ['top_nouns']  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì»¬ëŸ¼
    )
    
    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œì™¸ (ì„ íƒì‚¬í•­)
    text_cols = ['consulting_content', 'asr_segments']
    for col in text_cols:
        if col in train.columns:
            exclude_cols.append(col)
    
    # ì‹¤ì œ ì‚¬ìš©í•  íŠ¹ì„±ë“¤ ì„ íƒ
    feature_cols = [c for c in train.columns if c not in exclude_cols]
    
    print(f"âœ… ì‚¬ìš©í•  íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}")
    print(f"   ì£¼ìš” íŠ¹ì„±: {feature_cols[:10]}...")
    
    # 5) í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    print("\n[5ë‹¨ê³„] í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    
    X_train, y_train = train[feature_cols], train['label_id']
    X_val, y_val = val[feature_cols], val['label_id']
    X_test, y_test = test[feature_cols], test['label_id']
    
    # NaN ê°’ ì²˜ë¦¬ (0ìœ¼ë¡œ ì±„ìš°ê¸°)
    for X in [X_train, X_val, X_test]:
        X.fillna(0, inplace=True)
    
    print(f"âœ… íŠ¹ì„± í–‰ë ¬ í¬ê¸°: Train {X_train.shape}, Val {X_val.shape}, Test {X_test.shape}")
    print(f"   ë ˆì´ë¸” ë¶„í¬ (Train): {dict(pd.Series(y_train).value_counts().sort_index())}")
    
    # 6) í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘)
    print("\n[6ë‹¨ê³„] í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
    
    classes = np.unique(y_train)
    weights = compute_class_weight('balanced', classes=classes, y=y_train)
    class_weight = dict(zip(classes, weights))
    
    print(f"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weight}")
    
    # 7) LightGBM ëª¨ë¸ í•™ìŠµ
    print("\n[7ë‹¨ê³„] LightGBM ëª¨ë¸ í•™ìŠµ ì¤‘...")
    
    model = LGBMClassifier(
        objective='multiclass',
        num_class=len(label_encoder.classes_),
        n_estimators=200,
        learning_rate=0.05,
        max_depth=6,
        num_leaves=31,
        class_weight=class_weight,
        random_state=42,
        verbosity=-1  # ë¡œê·¸ ìµœì†Œí™”
    )
    
    # í•™ìŠµ ì‹¤í–‰
    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_val, y_val)],
        eval_metric='multi_logloss',
        callbacks=[
            early_stopping(stopping_rounds=20, verbose=True),
            log_evaluation(period=20)
        ]
    )
    
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    # 8) ëª¨ë¸ í‰ê°€
    print("\n[8ë‹¨ê³„] ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    
    # ê²€ì¦ ì„¸íŠ¸ í‰ê°€
    y_pred_val = model.predict(X_val)
    val_accuracy = accuracy_score(y_val, y_pred_val)
    
    print(f"\n--- ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥ ---")
    print(f"ì •í™•ë„: {val_accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(y_val, y_pred_val, target_names=label_encoder.classes_))
    
    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
    y_pred_test = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred_test)
    
    print(f"\n--- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥ ---")
    print(f"ì •í™•ë„: {test_accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))
    
    # 9) ëª¨ë¸ ë° ê´€ë ¨ ê°ì²´ ì €ì¥
    print("\n[9ë‹¨ê³„] ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘...")
    
    # ì €ì¥ í´ë” ìƒì„±
    os.makedirs('trained_models', exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    model_path = 'trained_models/counseling_quality_model.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ë ˆì´ë¸” ì¸ì½”ë” ì €ì¥
    encoder_path = 'trained_models/label_encoder.pkl'
    with open(encoder_path, 'wb') as f:
        pickle.dump(label_encoder, f)
    print(f"âœ… ë ˆì´ë¸” ì¸ì½”ë” ì €ì¥: {encoder_path}")
    
    # íŠ¹ì„± ì´ë¦„ ì €ì¥
    features_path = 'trained_models/feature_names.pkl'
    with open(features_path, 'wb') as f:
        pickle.dump(feature_cols, f)
    print(f"âœ… íŠ¹ì„± ì´ë¦„ ì €ì¥: {features_path}")
    
    # ë²”ì£¼í˜• ì¸ì½”ë”ë“¤ ì €ì¥
    if encoders:
        cat_encoders_path = 'trained_models/categorical_encoders.pkl'
        with open(cat_encoders_path, 'wb') as f:
            pickle.dump(encoders, f)
        print(f"âœ… ë²”ì£¼í˜• ì¸ì½”ë” ì €ì¥: {cat_encoders_path}")
    
    # ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
    results = {
        'validation_accuracy': val_accuracy,
        'test_accuracy': test_accuracy,
        'feature_count': len(feature_cols),
        'class_count': len(label_encoder.classes_),
        'classes': list(label_encoder.classes_)
    }
    
    results_path = 'results/model_training_results.json'
    os.makedirs('results', exist_ok=True)
    import json
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ… í•™ìŠµ ê²°ê³¼ ì €ì¥: {results_path}")
    
    print("\n" + "="*60)
    print("ğŸ‰ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")
    print("="*60)
    print(f"âœ… ê²€ì¦ ì •í™•ë„: {val_accuracy:.3f}")
    print(f"âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.3f}")
    print(f"âœ… ì €ì¥ëœ íŒŒì¼ë“¤:")
    print(f"   - ëª¨ë¸: {model_path}")
    print(f"   - ì¸ì½”ë”: {encoder_path}")
    print(f"   - íŠ¹ì„±: {features_path}")
    print("="*60)
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        exit(1)

