# -*- coding: utf-8 -*-
"""
auto_file_monitor.py
- data í´ë”ë¥¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ìƒˆ íŒŒì¼ ê°ì§€ì‹œ ìë™ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- ê²°ê³¼ë¥¼ text_features_all_v4.csvì— ëˆ„ì  ì €ì¥
"""

import os
import sys
import time
import threading
import subprocess
from pathlib import Path
from datetime import datetime
import pandas as pd

# watchdogì´ ì—†ìœ¼ë©´ ì„¤ì¹˜ ì•ˆë‚´
try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler
except ImportError:
    print("âŒ watchdog ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹: pip install watchdog")
    sys.exit(1)

class FileMonitorHandler(FileSystemEventHandler):
    """íŒŒì¼ ë³€ê²½ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, processor):
        self.processor = processor
        self.last_processed = {}  # íŒŒì¼ë³„ ë§ˆì§€ë§‰ ì²˜ë¦¬ ì‹œê°„
        self.processing_lock = threading.Lock()
        
    def on_created(self, event):
        """ìƒˆ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆì„ ë•Œ"""
        if not event.is_directory:
            self._handle_file_event(event.src_path, "ìƒì„±ë¨")
    
    def on_modified(self, event):
        """íŒŒì¼ì´ ìˆ˜ì •ë˜ì—ˆì„ ë•Œ"""
        if not event.is_directory:
            self._handle_file_event(event.src_path, "ìˆ˜ì •ë¨")
    
    def _handle_file_event(self, file_path, event_type):
        """íŒŒì¼ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        # JSON íŒŒì¼ë§Œ ì²˜ë¦¬
        if not file_path.endswith('.json'):
            return
        
        # data/classification í´ë”ì˜ íŒŒì¼ë§Œ ì²˜ë¦¬
        path_obj = Path(file_path)
        if 'data' not in path_obj.parts or 'classification' not in path_obj.parts:
            return
        
        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€ (5ì´ˆ ê°„ê²©)
        current_time = time.time()
        if (file_path in self.last_processed and 
            current_time - self.last_processed[file_path] < 5):
            return
        
        self.last_processed[file_path] = current_time
        
        # íŒŒì¼ì´ ì™„ì „íˆ ì“°ì—¬ì§ˆ ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
        time.sleep(2)
        
        # ì²˜ë¦¬ ì‹¤í–‰ (ìŠ¤ë ˆë“œ ì•ˆì „)
        with self.processing_lock:
            print(f"\nğŸ”” íŒŒì¼ {event_type}: {file_path}")
            self.processor.process_new_file(file_path)

class AutoProcessor:
    """ìë™ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.is_processing = False
        self.processed_files = set()
        
        # ì²˜ë¦¬ ê¸°ë¡ íŒŒì¼ ë¡œë“œ
        self.log_file = Path("auto_processing_log.txt")
        self._load_processed_files()
    
    def _load_processed_files(self):
        """ì´ì „ì— ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ë¡œë“œ"""
        if self.log_file.exists():
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            self.processed_files.add(line.strip())
                print(f"ğŸ“‹ ì´ì „ ì²˜ë¦¬ ê¸°ë¡: {len(self.processed_files)}ê°œ íŒŒì¼")
            except Exception as e:
                print(f"âš ï¸ ì²˜ë¦¬ ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _log_processed_file(self, file_path):
        """ì²˜ë¦¬ëœ íŒŒì¼ ê¸°ë¡"""
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(f"{file_path}\n")
            self.processed_files.add(file_path)
        except Exception as e:
            print(f"âš ï¸ ì²˜ë¦¬ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def process_new_file(self, file_path):
        """ìƒˆ íŒŒì¼ ì²˜ë¦¬"""
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
        if file_path in self.processed_files:
            print(f"â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼: {Path(file_path).name}")
            return
        
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
        if self.is_processing:
            print(f"â³ ë‹¤ë¥¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘... ëŒ€ê¸°: {Path(file_path).name}")
            return
        
        self.is_processing = True
        
        try:
            print(f"\n{'='*60}")
            print(f"ğŸš€ ìë™ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            print(f"ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"íŒŒì¼: {file_path}")
            print(f"{'='*60}")
            
            # 1ë‹¨ê³„: JSON ë³‘í•©
            print("\n[1ë‹¨ê³„] JSON íŒŒì¼ ë³‘í•© ì¤‘...")
            success = self._run_step("1_preprocessing_model_v3.py", "JSON ë³‘í•©")
            
            if not success:
                print("âŒ 1ë‹¨ê³„ ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
                return
            
            # 2ë‹¨ê³„: íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡ (í†µí•©)
            print("\n[2ë‹¨ê³„] íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡ ì¤‘...")
            success = self._run_step("2_extract_and_predict.py", "íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡")
            
            if not success:
                print("âŒ 2ë‹¨ê³„ ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
                return
            
            # ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
            self._log_processed_file(file_path)
            
            # ê²°ê³¼ ëˆ„ì 
            self._accumulate_results()
            
            print(f"\n{'='*60}")
            print(f"âœ… ìë™ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: output/text_features_all_v4.csv")
            print(f"{'='*60}")
            
        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
        finally:
            self.is_processing = False
    
    def _run_step(self, script_name, step_name):
        """ê°œë³„ ë‹¨ê³„ ì‹¤í–‰"""
        try:
            # Windows ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
            env = os.environ.copy()
            env['PYTHONIOENCODING'] = 'utf-8'
            env['PYTHONLEGACYWINDOWSSTDIO'] = '1'
            
            if os.name == 'nt':  # Windows
                try:
                    subprocess.run(['chcp', '65001'], shell=True, capture_output=True, check=False)
                except:
                    pass
            
            # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            result = subprocess.run(
                [sys.executable, script_name], 
                capture_output=True, 
                text=True, 
                timeout=600,  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
                env=env,
                encoding='utf-8',
                errors='ignore'
            )
            
            if result.returncode == 0:
                print(f"   âœ… {step_name} ì„±ê³µ")
                return True
            else:
                print(f"   âŒ {step_name} ì‹¤íŒ¨ (ì½”ë“œ: {result.returncode})")
                
                # ì‹¤ì œ ì¶œë ¥ íŒŒì¼ í™•ì¸ìœ¼ë¡œ ì„±ê³µ ì—¬ë¶€ ì¬íŒë‹¨
                if step_name == "JSON ë³‘í•©":
                    if Path("json_merge").exists():
                        print("   ğŸ” ì¶œë ¥ í´ë” í™•ì¸ - ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬")
                        return True
                elif step_name == "íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡":
                    if Path("output/text_features_all_v4.csv").exists():
                        print("   ğŸ” ì¶œë ¥ íŒŒì¼ í™•ì¸ - ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬")
                        return True
                
                return False
                
        except subprocess.TimeoutExpired:
            print(f"   â° {step_name} íƒ€ì„ì•„ì›ƒ")
            return False
        except Exception as e:
            print(f"   âŒ {step_name} ì˜ˆì™¸: {str(e)}")
            return False
    
    def _accumulate_results(self):
        """ê²°ê³¼ë¥¼ ëˆ„ì  CSVì— ì €ì¥"""
        try:
            current_file = Path("output/text_features_all_v4.csv")
            accumulated_file = Path("output/accumulated_results.csv")
            
            if not current_file.exists():
                print("âš ï¸ í˜„ì¬ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŒ")
                return
            
            # í˜„ì¬ ê²°ê³¼ ë¡œë“œ
            df_current = pd.read_csv(current_file, encoding='utf-8-sig')
            
            # ëˆ„ì  íŒŒì¼ì´ ìˆìœ¼ë©´ ë³‘í•©
            if accumulated_file.exists():
                df_accumulated = pd.read_csv(accumulated_file, encoding='utf-8-sig')
                
                # session_id ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°í•˜ë©° ë³‘í•©
                df_combined = pd.concat([df_accumulated, df_current]).drop_duplicates(
                    subset=['session_id'], keep='last'
                )
                
                print(f"ğŸ“Š ëˆ„ì  ê²°ê³¼ ì—…ë°ì´íŠ¸: {len(df_accumulated)} â†’ {len(df_combined)}ê°œ ì„¸ì…˜")
            else:
                df_combined = df_current
                print(f"ğŸ“Š ëˆ„ì  ê²°ê³¼ ì²« ìƒì„±: {len(df_combined)}ê°œ ì„¸ì…˜")
            
            # ëˆ„ì  íŒŒì¼ ì €ì¥
            df_combined.to_csv(accumulated_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ëˆ„ì  ê²°ê³¼ ì €ì¥: {accumulated_file}")
            
        except Exception as e:
            print(f"âŒ ëˆ„ì  ì €ì¥ ì‹¤íŒ¨: {str(e)}")

class FileMonitor:
    """íŒŒì¼ ëª¨ë‹ˆí„°ë§ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, watch_dir="data"):
        self.watch_dir = Path(watch_dir)
        self.processor = AutoProcessor()
        self.observer = Observer()
        
        # ëª¨ë‹ˆí„°ë§ ë””ë ‰í† ë¦¬ í™•ì¸
        if not self.watch_dir.exists():
            print(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.watch_dir}")
            print("   data í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            self.watch_dir.mkdir(parents=True, exist_ok=True)
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        print(f"ğŸ” íŒŒì¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        print(f"   ê°ì‹œ ë””ë ‰í† ë¦¬: {self.watch_dir.absolute()}")
        print(f"   ëŒ€ìƒ íŒŒì¼: data/classification/*.json")
        print(f"   ì²˜ë¦¬ ê²°ê³¼: output/text_features_all_v4.csv")
        print(f"   ëˆ„ì  ê²°ê³¼: output/accumulated_results.csv")
        print(f"{'='*50}")
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        event_handler = FileMonitorHandler(self.processor)
        
        # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.observer.schedule(event_handler, str(self.watch_dir), recursive=True)
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.observer.start()
        print("âœ… ëª¨ë‹ˆí„°ë§ í™œì„±í™”ë¨ (Ctrl+Cë¡œ ì¢…ë£Œ)")
        
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì¤‘...")
            self.stop_monitoring()
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.observer.stop()
        self.observer.join()
        print("âœ… ëª¨ë‹ˆí„°ë§ ì¢…ë£Œë¨")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ìƒë‹´ ë°ì´í„° ìë™ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    print("="*50)
    
    # í•™ìŠµëœ ëª¨ë¸ í™•ì¸
    model_dir = Path("trained_models")
    required_files = [
        "counseling_quality_model.pkl",
        "label_encoder.pkl", 
        "feature_names.pkl"
    ]
    
    missing_files = [f for f in required_files if not (model_dir / f).exists()]
    if missing_files:
        print(f"âŒ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_files}")
        print("   ë¨¼ì € train_from_dataset_v4.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.")
        return
    
    print("âœ… í•™ìŠµëœ ëª¨ë¸ í™•ì¸ ì™„ë£Œ")
    
    # íŒŒì¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    monitor = FileMonitor()
    monitor.start_monitoring()

if __name__ == "__main__":
    main() 