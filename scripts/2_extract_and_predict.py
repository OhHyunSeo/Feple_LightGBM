# -*- coding: utf-8 -*-
"""
2_extract_and_predict.py
- íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡ì„ í•œë²ˆì— ìˆ˜í–‰
- ê²°ê³¼ë¥¼ text_features_all_v4.csvì— ì €ì¥ (ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨)
"""

import os
import sys
import glob
import json
import re
import pickle
import subprocess
from collections import Counter
from pathlib import Path
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import lightgbm as lgb

def extract_and_predict():
    """íŠ¹ì„± ì¶”ì¶œê³¼ ì˜ˆì¸¡ì„ ì—°ì†ìœ¼ë¡œ ìˆ˜í–‰"""
    print("="*60)
    print("íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡ í†µí•© ì²˜ë¦¬")
    print("="*60)
    
    # 1) 2ë‹¨ê³„ íŠ¹ì„± ì¶”ì¶œ ì‹¤í–‰
    print("\n[1ë‹¨ê³„] í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ ì¤‘...")
    try:
        # Windows ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['PYTHONLEGACYWINDOWSSTDIO'] = '1'
        
        # Windowsì—ì„œ ì½”ë“œí˜ì´ì§€ë¥¼ UTF-8ë¡œ ì„¤ì •
        if os.name == 'nt':  # Windows
            try:
                subprocess.run(['chcp', '65001'], shell=True, capture_output=True, check=False)
            except:
                pass
        
        # 2ë‹¨ê³„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        result = subprocess.run(
            [sys.executable, "2_coloums_extraction_v3_json2csv.py"], 
            capture_output=True, 
            text=True, 
            timeout=600,
            env=env,
            encoding='utf-8',
            errors='ignore'
        )
        
        # ê²°ê³¼ í™•ì¸
        feature_file = "output/text_features_all_v4.csv"
        if Path(feature_file).exists():
            print("âœ… íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")
        else:
            print("âŒ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨ - ì¶œë ¥ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
            return False
            
    except Exception as e:
        print(f"âŒ íŠ¹ì„± ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False
    
    # 2) í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    print("\n[2ë‹¨ê³„] í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    try:
        model_dir = Path("trained_models")
        
        # ëª¨ë¸ íŒŒì¼ë“¤ ë¡œë“œ
        with open(model_dir / "counseling_quality_model.pkl", 'rb') as f:
            model = pickle.load(f)
        
        with open(model_dir / "label_encoder.pkl", 'rb') as f:
            label_encoder = pickle.load(f)
        
        with open(model_dir / "feature_names.pkl", 'rb') as f:
            feature_names = pickle.load(f)
        
        # ë²”ì£¼í˜• ì¸ì½”ë” ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        categorical_encoders = {}
        categorical_file = model_dir / "categorical_encoders.pkl"
        if categorical_file.exists():
            with open(categorical_file, 'rb') as f:
                categorical_encoders = pickle.load(f)
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   - ë¶„ë¥˜ í´ë˜ìŠ¤: {label_encoder.classes_}")
        print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(feature_names)}")
        print(f"   - ë²”ì£¼í˜• ì¸ì½”ë”: {len(categorical_encoders)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False
    
    # 3) íŠ¹ì„± ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    print("\n[3ë‹¨ê³„] íŠ¹ì„± ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    try:
        # CSV íŒŒì¼ ë¡œë“œ
        df_features = pd.read_csv(feature_file, encoding='utf-8-sig')
        
        # ì¤‘ë³µ ì œê±° ë° session_id íƒ€ì… í†µì¼
        df_features = df_features.drop_duplicates(subset=['session_id'])
        df_features['session_id'] = df_features['session_id'].astype(str)
        
        print(f"   ğŸ“Š ì²˜ë¦¬í•  ì„¸ì…˜ ìˆ˜: {len(df_features)}")
        
        # ë ˆì´ë¸” íŒŒì¼ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        labels_file = "columns_extraction_all/preprocessing/session_labels.csv"
        df_labels = None
        if Path(labels_file).exists():
            df_labels = pd.read_csv(labels_file, encoding='utf-8-sig', dtype={'session_id': str})
            print(f"   ğŸ“‹ ë ˆì´ë¸” ì •ë³´: {len(df_labels)}ê°œ ì„¸ì…˜")
        
        # ë°ì´í„° ë³‘í•©
        if df_labels is not None:
            df = df_features.merge(df_labels, on='session_id', how='left')
        else:
            df = df_features.copy()
            df['result_label'] = None
        
        # ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©
        for col, encoder in categorical_encoders.items():
            if col in df.columns:
                print(f"   ğŸ”„ ë²”ì£¼í˜• ì¸ì½”ë”©: {col}")
                original_values = df[col].fillna('missing').astype(str)
                try:
                    df[col] = encoder.transform(original_values)
                except ValueError:
                    # ìƒˆë¡œìš´ ê°’ì´ ìˆëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                    print(f"     âš ï¸ ìƒˆë¡œìš´ ë²”ì£¼ ë°œê²¬, ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬")
                    known_classes = set(encoder.classes_)
                    df[col] = [encoder.transform(['missing'])[0] if val not in known_classes 
                              else encoder.transform([val])[0] for val in original_values]
        
        # íŠ¹ì„± ì„ íƒ ë° ì •ë ¬
        missing_features = []
        for feature in feature_names:
            if feature not in df.columns:
                missing_features.append(feature)
                df[feature] = 0  # ëˆ„ë½ëœ íŠ¹ì„±ì€ 0ìœ¼ë¡œ ì±„ì›€
        
        if missing_features:
            print(f"   âš ï¸ ëˆ„ë½ëœ íŠ¹ì„± {len(missing_features)}ê°œë¥¼ 0ìœ¼ë¡œ ì±„ì›€")
        
        # ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„
        X_predict = df[feature_names].copy()
        X_predict.fillna(0, inplace=True)
        
        # ë°ì´í„° íƒ€ì… ë³€í™˜
        for col in feature_names:
            X_predict[col] = pd.to_numeric(X_predict[col], errors='coerce').fillna(0)
        
        print(f"   âœ… ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_predict.shape}")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return False
    
    # 4) ì˜ˆì¸¡ ìˆ˜í–‰
    print("\n[4ë‹¨ê³„] ìƒë‹´ í’ˆì§ˆ ì˜ˆì¸¡ ì¤‘...")
    try:
        # ì˜ˆì¸¡ ì‹¤í–‰
        y_pred_proba = model.predict_proba(X_predict)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # ì˜ˆì¸¡ ê²°ê³¼ ë³€í™˜
        predicted_labels = label_encoder.inverse_transform(y_pred)
        confidence_scores = np.max(y_pred_proba, axis=1)
        
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì›ë³¸ DataFrameì— ì¶”ê°€
        df_features['predicted_label'] = predicted_labels
        df_features['confidence'] = confidence_scores
        
        # ì‹¤ì œ ë ˆì´ë¸”ë„ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if df_labels is not None:
            # ì‹¤ì œ ë ˆì´ë¸” ë³‘í•©
            df_with_actual = df_features.merge(df_labels, on='session_id', how='left')
            df_features['actual_label'] = df_with_actual['result_label']
        
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ")
        
        # ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬
        pred_counts = pd.Series(predicted_labels).value_counts()
        print(f"\nğŸ“‹ ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬:")
        for label, count in pred_counts.items():
            percentage = count / len(predicted_labels) * 100
            print(f"   {label}: {count}ê°œ ({percentage:.1f}%)")
        
        # ì‹ ë¢°ë„ í†µê³„
        print(f"\nğŸ“Š ì‹ ë¢°ë„ í†µê³„:")
        print(f"   í‰ê· : {confidence_scores.mean():.3f}")
        print(f"   ìµœì†Œ: {confidence_scores.min():.3f}")
        print(f"   ìµœëŒ€: {confidence_scores.max():.3f}")
        high_confidence = (confidence_scores >= 0.8).sum()
        print(f"   ê³ ì‹ ë¢°ë„(â‰¥0.8): {high_confidence}ê°œ ({high_confidence/len(confidence_scores)*100:.1f}%)")
        
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return False
    
    # 5) ê²°ê³¼ ì €ì¥
    print("\n[5ë‹¨ê³„] ê²°ê³¼ ì €ì¥ ì¤‘...")
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        # CSV íŒŒì¼ì— ì €ì¥ (ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°)
        output_file = output_dir / "text_features_all_v4.csv"
        df_features.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        print(f"   ì»¬ëŸ¼ ìˆ˜: {len(df_features.columns)}")
        print(f"   í–‰ ìˆ˜: {len(df_features)}")
        
        # ë³„ë„ë¡œ ì˜ˆì¸¡ ê²°ê³¼ë§Œ ì €ì¥
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        prediction_columns = ['session_id', 'predicted_label', 'confidence']
        if 'actual_label' in df_features.columns:
            prediction_columns.append('actual_label')
        
        predictions_df = df_features[prediction_columns]
        predictions_file = results_dir / "counseling_quality_predictions.csv"
        predictions_df.to_csv(predictions_file, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ë³„ë„ ì €ì¥: {predictions_file}")
        
        # ë¯¸ë¦¬ë³´ê¸°
        print(f"\nğŸ” ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 3ê°œ):")
        for _, row in df_features.head(3).iterrows():
            actual_info = f" (ì‹¤ì œ: {row.get('actual_label', 'N/A')})" if 'actual_label' in df_features.columns else ""
            print(f"   ì„¸ì…˜ {row['session_id']}: {row['predicted_label']} (ì‹ ë¢°ë„: {row['confidence']:.3f}){actual_info}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ + ìƒë‹´ í’ˆì§ˆ ì˜ˆì¸¡ í†µí•© ì‹œìŠ¤í…œ")
    print("="*50)
    
    # í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ í™•ì¸
    model_dir = Path("trained_models")
    required_files = [
        "counseling_quality_model.pkl",
        "label_encoder.pkl", 
        "feature_names.pkl"
    ]
    
    missing_files = [f for f in required_files if not (model_dir / f).exists()]
    if missing_files:
        print(f"âŒ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_files}")
        print("   ë¨¼ì € train_from_dataset_v4.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.")
        return False
    
    # í†µí•© ì²˜ë¦¬ ì‹¤í–‰
    success = extract_and_predict()
    
    if success:
        print("\n" + "="*60)
        print("ğŸ‰ íŠ¹ì„± ì¶”ì¶œ + ì˜ˆì¸¡ ì™„ë£Œ!")
        print("   ğŸ“„ output/text_features_all_v4.csv (ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨)")
        print("   ğŸ“„ results/counseling_quality_predictions.csv (ì˜ˆì¸¡ ì „ìš©)")
        print("="*60)
    else:
        print("\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨")
    
    return success

if __name__ == "__main__":
    main() 