# -*- coding: utf-8 -*-
"""
dataset_v4 í´ë”ì˜ íŒŒì¼ë“¤ë¡œ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥
"""

import os
import pandas as pd
import numpy as np
import pickle
import lightgbm as lgb
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.utils.class_weight import compute_class_weight
from lightgbm import LGBMClassifier, early_stopping, log_evaluation

def main():
    print("="*60)
    print("dataset_v4ë¡œ ìƒë‹´ í’ˆì§ˆ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")
    print("="*60)
    
    # 1) ë°ì´í„° ë¡œë“œ
    print("\n[1ë‹¨ê³„] dataset_v4 ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        train = pd.read_csv('dataset_v4/train.csv', encoding='utf-8-sig')
        val   = pd.read_csv('dataset_v4/val.csv',   encoding='utf-8-sig')
        test  = pd.read_csv('dataset_v4/test.csv',  encoding='utf-8-sig')
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"   Train: {train.shape}, Val: {val.shape}, Test: {test.shape}")
        print(f"   ì»¬ëŸ¼ ìˆ˜: {len(train.columns)}")
    except FileNotFoundError as e:
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return False
    
    # 2) ë ˆì´ë¸” í™•ì¸ ë° ì¸ì½”ë”©
    print("\n[2ë‹¨ê³„] ë ˆì´ë¸” í™•ì¸ ë° ì¸ì½”ë”© ì¤‘...")
    
    # result_label ì»¬ëŸ¼ í™•ì¸
    if 'result_label' not in train.columns:
        print("âŒ result_label ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(train.columns)}")
        return False
    
    # ë ˆì´ë¸” ë¶„í¬ í™•ì¸
    print(f"   ë ˆì´ë¸” ë¶„í¬: {train['result_label'].value_counts().to_dict()}")
    
    # ë ˆì´ë¸” ì¸ì½”ë”©
    all_targets = pd.concat([
        train['result_label'],
        val['result_label'],
        test['result_label']
    ]).astype(str)
    
    label_encoder = LabelEncoder().fit(all_targets)
    
    # ê° ë°ì´í„°ì…‹ì— ì ìš©
    for df in [train, val, test]:
        df['label_id'] = label_encoder.transform(df['result_label'].astype(str))
    
    print(f"âœ… ë ˆì´ë¸” í´ë˜ìŠ¤: {list(label_encoder.classes_)}")
    print(f"   í´ë˜ìŠ¤ ê°œìˆ˜: {len(label_encoder.classes_)}")
    
    # 3) íŠ¹ì„± ì„ íƒ ë° íƒ€ì… ì²˜ë¦¬
    print("\n[3ë‹¨ê³„] í•™ìŠµìš© íŠ¹ì„± ì„ íƒ ë° ë°ì´í„° íƒ€ì… ì²˜ë¦¬ ì¤‘...")
    
    # ì œì™¸í•  ì»¬ëŸ¼ë“¤ ì •ì˜
    exclude_cols = [
        'session_id', 'result_label', 'label_id',
        'top_nouns', 'consulting_content', 'asr_segments',
        'Unnamed: 32'  # í˜¹ì‹œ ìˆì„ ìˆ˜ ìˆëŠ” unnamed ì»¬ëŸ¼
    ]
    
    # Object íƒ€ì… ì»¬ëŸ¼ë“¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¸ì½”ë” ì €ì¥ì†Œ
    categorical_encoders = {}
    
    # ì „ì²´ ì»¬ëŸ¼ íƒ€ì… í™•ì¸ ë° ì²˜ë¦¬
    for col in train.columns:
        if col not in exclude_cols:
            # NaNì´ ë§ì€ ì»¬ëŸ¼ ì œì™¸
            nan_ratio = train[col].isna().mean()
            if nan_ratio > 0.5:  # 50% ì´ìƒ NaNì¸ ì»¬ëŸ¼ ì œì™¸
                exclude_cols.append(col)
                print(f"   ì œì™¸ (NaN {nan_ratio:.1%}): {col}")
                continue
            
            # Object íƒ€ì… ì»¬ëŸ¼ ì²˜ë¦¬
            if train[col].dtype == 'object':
                print(f"   ì¸ì½”ë”© ì²˜ë¦¬: {col} (object íƒ€ì…)")
                
                # ëª¨ë“  ë°ì´í„°ì…‹ì˜ í•´ë‹¹ ì»¬ëŸ¼ì„ í•©ì³ì„œ ì¸ì½”ë” í•™ìŠµ
                all_values = pd.concat([
                    train[col].fillna('missing'),
                    val[col].fillna('missing'),
                    test[col].fillna('missing')
                ]).astype(str)
                
                # LabelEncoder ìƒì„± ë° í•™ìŠµ
                encoder = LabelEncoder()
                encoder.fit(all_values)
                categorical_encoders[col] = encoder
                
                # ê° ë°ì´í„°ì…‹ì— ì ìš©
                for df in [train, val, test]:
                    df[col] = encoder.transform(df[col].fillna('missing').astype(str))
    
    # ì‹¤ì œ ì‚¬ìš©í•  íŠ¹ì„±ë“¤ ì„ íƒ
    feature_cols = [c for c in train.columns if c not in exclude_cols]
    
    print(f"âœ… ì‚¬ìš©í•  íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}")
    print(f"   ì£¼ìš” íŠ¹ì„±: {feature_cols[:10]}...")
    print(f"   ì¸ì½”ë”©ëœ ë²”ì£¼í˜• íŠ¹ì„±: {len(categorical_encoders)}ê°œ")
    
    # 4) í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    print("\n[4ë‹¨ê³„] í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    
    X_train, y_train = train[feature_cols].copy(), train['label_id']
    X_val, y_val = val[feature_cols].copy(), val['label_id']
    X_test, y_test = test[feature_cols].copy(), test['label_id']
    
    # NaN ê°’ ì²˜ë¦¬ (0ìœ¼ë¡œ ì±„ìš°ê¸°)
    for X in [X_train, X_val, X_test]:
        X.fillna(0, inplace=True)
    
    # ë°ì´í„° íƒ€ì… ê°•ì œ ë³€í™˜ (ëª¨ë“  ì»¬ëŸ¼ì„ numericìœ¼ë¡œ)
    for col in feature_cols:
        for X in [X_train, X_val, X_test]:
            X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)
    
    print(f"âœ… íŠ¹ì„± í–‰ë ¬ í¬ê¸°: Train {X_train.shape}, Val {X_val.shape}, Test {X_test.shape}")
    print(f"   ë ˆì´ë¸” ë¶„í¬ (Train): {dict(pd.Series(y_train).value_counts().sort_index())}")
    print(f"   ë°ì´í„° íƒ€ì… í™•ì¸: {X_train.dtypes.value_counts().to_dict()}")
    
    # 5) í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘)
    print("\n[5ë‹¨ê³„] í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
    
    classes = np.unique(y_train)
    weights = compute_class_weight('balanced', classes=classes, y=y_train)
    class_weight = dict(zip(classes, weights))
    
    print(f"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weight}")
    
    # 6) LightGBM ëª¨ë¸ í•™ìŠµ
    print("\n[6ë‹¨ê³„] LightGBM ëª¨ë¸ í•™ìŠµ ì¤‘...")
    
    model = LGBMClassifier(
        objective='multiclass',
        num_class=len(label_encoder.classes_),
        n_estimators=200,
        learning_rate=0.05,
        max_depth=6,
        num_leaves=31,
        class_weight=class_weight,
        random_state=42,
        verbosity=-1
    )
    
    # í•™ìŠµ ì‹¤í–‰
    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_val, y_val)],
        eval_metric='multi_logloss',
        callbacks=[
            early_stopping(stopping_rounds=20, verbose=True),
            log_evaluation(period=20)
        ]
    )
    
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    # 7) ëª¨ë¸ í‰ê°€
    print("\n[7ë‹¨ê³„] ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    
    # ê²€ì¦ ì„¸íŠ¸ í‰ê°€
    y_pred_val = model.predict(X_val)
    val_accuracy = accuracy_score(y_val, y_pred_val)
    
    print(f"\n--- ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥ ---")
    print(f"ì •í™•ë„: {val_accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(y_val, y_pred_val, target_names=label_encoder.classes_))
    
    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
    y_pred_test = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred_test)
    
    print(f"\n--- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥ ---")
    print(f"ì •í™•ë„: {test_accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))
    
    # 8) ëª¨ë¸ ë° ê´€ë ¨ ê°ì²´ ì €ì¥
    print("\n[8ë‹¨ê³„] ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘...")
    
    # ì €ì¥ í´ë” ìƒì„±
    os.makedirs('trained_models', exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    model_path = 'trained_models/counseling_quality_model.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ë ˆì´ë¸” ì¸ì½”ë” ì €ì¥
    encoder_path = 'trained_models/label_encoder.pkl'
    with open(encoder_path, 'wb') as f:
        pickle.dump(label_encoder, f)
    print(f"âœ… ë ˆì´ë¸” ì¸ì½”ë” ì €ì¥: {encoder_path}")
    
    # íŠ¹ì„± ì´ë¦„ ì €ì¥
    features_path = 'trained_models/feature_names.pkl'
    with open(features_path, 'wb') as f:
        pickle.dump(feature_cols, f)
    print(f"âœ… íŠ¹ì„± ì´ë¦„ ì €ì¥: {features_path}")
    
    # ë²”ì£¼í˜• ì¸ì½”ë” ì €ì¥
    categorical_path = 'trained_models/categorical_encoders.pkl'
    with open(categorical_path, 'wb') as f:
        pickle.dump(categorical_encoders, f)
    print(f"âœ… ë²”ì£¼í˜• ì¸ì½”ë” ì €ì¥: {categorical_path}")
    
    # ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
    results = {
        'validation_accuracy': val_accuracy,
        'test_accuracy': test_accuracy,
        'feature_count': len(feature_cols),
        'class_count': len(label_encoder.classes_),
        'classes': list(label_encoder.classes_),
        'feature_names': feature_cols,
        'categorical_features': list(categorical_encoders.keys())
    }
    
    results_path = 'results/model_training_results.json'
    os.makedirs('results', exist_ok=True)
    import json
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ… í•™ìŠµ ê²°ê³¼ ì €ì¥: {results_path}")
    
    print("\n" + "="*60)
    print("ğŸ‰ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")
    print("="*60)
    print(f"âœ… ê²€ì¦ ì •í™•ë„: {val_accuracy:.3f}")
    print(f"âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.3f}")
    print(f"âœ… ë¶„ë¥˜ í´ë˜ìŠ¤: {label_encoder.classes_}")
    print(f"âœ… ì €ì¥ëœ íŒŒì¼ë“¤:")
    print(f"   - ëª¨ë¸: {model_path}")  
    print(f"   - ì¸ì½”ë”: {encoder_path}")
    print(f"   - íŠ¹ì„±: {features_path}")
    print(f"   - ë²”ì£¼í˜• ì¸ì½”ë”: {categorical_path}")
    print("="*60)
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        exit(1) 